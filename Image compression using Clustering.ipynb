{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><img src='http://i.stack.imgur.com/UJl1A.jpg' width='600px'></center>"},{"metadata":{},"cell_type":"markdown","source":"**Kernel Reference**: [Scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html)"},{"metadata":{},"cell_type":"markdown","source":"## Import necessary packages\nWe will need these along the way, I have tried to explain the purpose of each libraries as comments."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# The below two are visualization libraires\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# for calculating interval\nfrom time import time\n\nplt.rcParams['figure.figsize'] = 10,8 # setting default figure size for the kernel\n\n# for clustering image pixels\nfrom sklearn.cluster import KMeans \n# for simple image processing tasks\nfrom skimage import io","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load a sample photo\n\nIf you want to try out your own image feel free to replace the URL with your favorite image. Here, we will be working with this sweet lil guy."},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTzLzdD4MoAPP3I_JjrxndAqKg1zXtEnaODwsHbH6il9BL3Qt61'\nimg_original = io.imread(url)\nplt.axis('off')\nplt.imshow(img_original)\nplt.title('Our buddy for the experiment !')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make sure the model understands you\n\nAs most of you know, computers unlike humans interpret images as numbers (to be more specific, numerical array). So we must take care (preprocess) the image prior to any analytical operation.\n\nBelow, we will be performing the following operations:\n- Normalization, color range is from 0 to 255 and dividing by max value will scale it down to 0 - 1 range.\n- Reshaping, the clustering algorithm is expecting a max of 2 dimension array so we will have to make necessary adjustments for it to work properly. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unit normalizing \nimg = np.array(img_original,dtype=float) / 255\n\n# Save the dimensions, we will be need them later\nw, h, d = original_shape = img.shape\nprint('Original Shape'.center(20,'='))\nprint(img.shape)\n\n# image_array size - w*h , d\nimage_array = img.reshape(-1,d)\nprint('ReShaped'.center(20,'='))\nprint(image_array.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The real work begins\n\nNow, the clustering algorithm will find common cluster based on which we can reduce the colors in the image. Even before beginning we will have to specify the number of clusters (common color points) one would like to have in the final image. I have randomly chosen `64` and `32` as the number of clusters. Try out values like `128` and `16` to see more drastic change.\n\n**Note:** As the number of clusters increases, the image will be closer to the original image but at the cost of higher computational cost."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_colours = [64,32]\n\n# 64 colour image\nt0 = time()\nkmeans64 = KMeans(n_clusters = n_colours[0],random_state=42,verbose=2,n_jobs=-1).fit(image_array)\n\nprint(f'Completed 64 clusters in {round(time()-t0,2)} seconds.')\n\n# 32 colour image\nt0 = time()\nkmeans32 = KMeans(n_clusters = n_colours[1],random_state=42,verbose=2,n_jobs=-1)\nkmeans32.fit(image_array)\n\nprint(f'Completed 32 clusters in {round(time()-t0,2)} seconds.')\n\nlabels64 = kmeans64.labels_\nlabels32 = kmeans32.labels_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Within cluster sum of square error, it measures the variance of datapoints inside a cluster.\n\nUse this to know how well the clustering worked. The lower, the better."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Within cluster sum of square error for {n_colours[0]} clusters = {round(kmeans64.inertia_,2)}')\nprint(f'Within cluster sum of square error for {n_colours[1]} clusters = {round(kmeans32.inertia_,2)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sample check\nWhat labels has the 64 cluster model produced?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the compressed values\ncompressed = pd.DataFrame(image_array,columns=['Red','Green','Blue'])\ncompressed['labels'] = kmeans64.labels_\ncompressed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper function"},{"metadata":{},"cell_type":"markdown","source":"This function will utilize the cluster center details to reconstruct a simplified version of the image.\n\nFunction logic:\n- Create a new image having similar shape of the original image\n- For each pixel value check the cluster label assigned\n- Based on the label, find the common color/centroid value (eg: the value found in ```kmeans64.cluster_centroids_```)\n- In the new image, fill the corresponding pixel position with the new color value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recreate image\ndef recreate_image(centroids, labels, w, h):\n    # centroids variable are calculated from the flattened image\n    # centroids: w*h, d \n    # so each row depicts the values per depth\n    d = centroids.shape[1]\n    image = np.zeros((w, h, d))\n    label_idx = 0\n    for i in range(w):\n        for j in range(h):\n            # filling values in new image with centroid values\n            image[i][j] = centroids[labels[label_idx]]\n            label_idx += 1\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time for the results\n\nü•Å *drum roll please* ü•Å"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(132)\nplt.axis('off')\nplt.title('Original image')\nplt.imshow(img)\n\nplt.subplot(131)\nplt.axis('off')\nplt.title('Compressed image (64 colors, K-Means)')\nplt.imshow(recreate_image(kmeans64.cluster_centers_, labels64, w, h))\n\nplt.subplot(133)\nplt.axis('off')\nplt.title('Compressed image (32 colors, K-Means)')\nplt.imshow(recreate_image(kmeans32.cluster_centers_, labels32, w, h))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You might not notice much difference at first but try to zoom the kernel and take a look at it again."},{"metadata":{},"cell_type":"markdown","source":"## To do\n- [X] Use custom images\n- [X] Add jobs for faster execution.\n- [ ] Compare performance with other clustering methods (hierarchical and density based)\n- [ ] % change of size per image\n\n*If you have been this far and enjoyed the kernel, let's give an upvote for this kernel.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}